#!/usr/bin/env python3
"""
Visualize Pareto Frontier from Schedule Characterization

This script reads CSV files generated by the schedule characterizer and
creates visualizations of the tile size vs energy Pareto frontier.

Note: Energy vs Latency/Throughput/L2 are NOT valid Pareto tradeoffs:
- Energy vs Latency: Correlated (good schedules have both low)
- Energy vs Throughput: Execution-dependent (not a resource constraint)
- Energy vs L2 Footprint: Many points with same L2, different energy

We plot Tile Size vs Energy which shows THE FUNDAMENTAL TRADEOFF:
- Large tiles → fewer DRAM fetches → LOWER energy
- Small tiles → more DRAM fetches → HIGHER energy

Usage:
    python visualize_pareto_frontier.py pareto_frontier.csv
"""

import sys
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
from pathlib import Path

def plot_pareto_frontier(csv_file, output_prefix=None):
    """Plot Pareto frontier from CSV file"""

    # Read data
    df = pd.read_csv(csv_file)

    if output_prefix is None:
        output_prefix = Path(csv_file).stem

    # Create figure with multiple subplots
    fig, axes = plt.subplots(2, 2, figsize=(15, 12))
    fig.suptitle(f'Pareto Frontier Analysis: {Path(csv_file).name}',
                 fontsize=16, fontweight='bold')

    # 1. Tile Size vs Energy scatter plot (PROPER PARETO TRADEOFF)
    ax = axes[0, 0]
    if 'Tile_Size' in df.columns:
        # Plot all points
        if 'Strategy' in df.columns:
            strategies = df['Strategy'].unique()
            colors = ['red', 'blue', 'green', 'orange', 'purple']
            for i, strategy in enumerate(strategies):
                strategy_df = df[df['Strategy'] == strategy]
                ax.scatter(strategy_df['Tile_Size'], strategy_df['Energy_pJ'],
                          alpha=0.6, s=50, c=colors[i % len(colors)],
                          label=strategy)
        else:
            ax.scatter(df['Tile_Size'], df['Energy_pJ'],
                      alpha=0.6, s=50, c='blue', label='All schedules')

        ax.set_xlabel('Tile Size (elements)', fontsize=12)
        ax.set_ylabel('Energy (pJ)', fontsize=12)
        ax.set_title('Pareto Frontier: Tile Size vs Energy')
        ax.set_xscale('log')
        ax.set_yscale('log')

        # Add annotation explaining the tradeoff
        ax.text(0.05, 0.95, 'Large tiles → Fewer DRAM fetches → Low energy\nSmall tiles → More DRAM fetches → High energy',
                transform=ax.transAxes, fontsize=9, verticalalignment='top',
                bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))
    else:
        # Fallback if tile size not available
        ax.scatter(df['Energy_pJ'], df['Latency_cycles'],
                  alpha=0.6, s=50, c='blue', label='All schedules')
        ax.set_xlabel('Energy (pJ)', fontsize=12)
        ax.set_ylabel('Latency (cycles)', fontsize=12)
        ax.set_title('Energy vs Latency (correlated, not Pareto)')
        ax.set_xscale('log')
        ax.set_yscale('log')
    ax.grid(True, alpha=0.3)
    ax.legend()

    # 2. Slowdown analysis
    ax = axes[0, 1]
    if 'Energy_Slowdown' in df.columns and 'Latency_Slowdown' in df.columns:
        ax.scatter(df['Energy_Slowdown'], df['Latency_Slowdown'],
                  alpha=0.6, s=50, c='green')
        ax.axhline(y=1.0, color='r', linestyle='--', label='Ideal')
        ax.axvline(x=1.0, color='r', linestyle='--')
        ax.set_xlabel('Energy Slowdown (vs Ideal)', fontsize=12)
        ax.set_ylabel('Latency Slowdown (vs Ideal)', fontsize=12)
        ax.set_title('Slowdown Analysis')
        ax.grid(True, alpha=0.3)
        ax.legend()

    # 3. Throughput vs Latency (for information only - shows performance characteristics)
    ax = axes[1, 0]
    if 'Throughput_GFLOPS' in df.columns and 'Strategy' in df.columns:
        strategies = df['Strategy'].unique()
        colors = ['red', 'blue', 'green', 'orange', 'purple']

        for i, strategy in enumerate(strategies):
            strategy_df = df[df['Strategy'] == strategy]
            ax.scatter(strategy_df['Latency_cycles'], strategy_df['Throughput_GFLOPS'],
                      alpha=0.6, s=50, c=colors[i % len(colors)],
                      label=strategy)

        ax.set_xlabel('Latency (cycles)', fontsize=12)
        ax.set_ylabel('Throughput (GFLOP/s)', fontsize=12)
        ax.set_title('Throughput vs Latency (Reference Only)')
        ax.set_xscale('log')
        ax.set_yscale('log')
        ax.grid(True, alpha=0.3)
        ax.legend()

        # Add note
        ax.text(0.05, 0.05, 'Lower latency → Higher throughput\n(Inversely related)',
                transform=ax.transAxes, fontsize=9, verticalalignment='bottom',
                bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.5))

    # 4. Tensor shape distribution
    ax = axes[1, 1]
    if 'M' in df.columns and 'N' in df.columns and 'K' in df.columns:
        # Create size metric (product of dimensions)
        df['Size'] = df['M'] * df['N'] * df['K']

        # Check if we have variation in sizes
        if df['Size'].nunique() > 1:
            # Bin by size only if we have multiple unique sizes
            size_bins = np.logspace(np.log10(df['Size'].min()),
                                   np.log10(df['Size'].max()), 20)
            df['Size_bin'] = pd.cut(df['Size'], bins=size_bins, duplicates='drop')

            # Average energy per bin
            bin_stats = df.groupby('Size_bin').agg({
                'Energy_pJ': 'mean',
                'Latency_cycles': 'mean',
                'Size': 'mean'
            }).dropna()

            ax.scatter(bin_stats['Size'], bin_stats['Energy_pJ'],
                      s=100, c='purple', alpha=0.6)
            ax.set_xscale('log')
            ax.set_yscale('log')
        else:
            # All same size - just plot raw data
            ax.scatter(df['Size'], df['Energy_pJ'],
                      s=100, c='purple', alpha=0.6)
            # Don't use log scale if only one point

        ax.set_xlabel('Tensor Size (M×N×K)', fontsize=12)
        ax.set_ylabel('Average Energy (pJ)', fontsize=12)
        ax.set_title('Energy vs Tensor Size')
        ax.grid(True, alpha=0.3, which='both')

    plt.tight_layout()

    # Save figure
    output_file = f'{output_prefix}_visualization.png'
    plt.savefig(output_file, dpi=300, bbox_inches='tight')
    print(f'Saved visualization to {output_file}')

    # Show if interactive
    if sys.stdout.isatty():
        plt.show()

    return fig

def print_statistics(csv_file):
    """Print statistics about the Pareto frontier"""

    df = pd.read_csv(csv_file)

    print(f"\n{'='*70}")
    print(f"Pareto Frontier Statistics: {Path(csv_file).name}")
    print(f"{'='*70}\n")

    print(f"Total points: {len(df)}")

    if 'Strategy' in df.columns:
        print(f"\nStrategy distribution:")
        for strategy, count in df['Strategy'].value_counts().items():
            pct = 100.0 * count / len(df)
            print(f"  {strategy:20s}: {count:4d} ({pct:5.1f}%)")

    print(f"\nEnergy range:")
    print(f"  Min:    {df['Energy_pJ'].min():12.1f} pJ")
    print(f"  Max:    {df['Energy_pJ'].max():12.1f} pJ")
    print(f"  Mean:   {df['Energy_pJ'].mean():12.1f} pJ")
    print(f"  Median: {df['Energy_pJ'].median():12.1f} pJ")

    if 'Tile_Size' in df.columns:
        print(f"\nTile Size range:")
        print(f"  Min:    {df['Tile_Size'].min():12.0f} elements")
        print(f"  Max:    {df['Tile_Size'].max():12.0f} elements")
        print(f"  Mean:   {df['Tile_Size'].mean():12.0f} elements")
        print(f"  Median: {df['Tile_Size'].median():12.0f} elements")

    if 'L2_Footprint_bytes' in df.columns:
        print(f"\nL2 Footprint range:")
        print(f"  Min:    {df['L2_Footprint_bytes'].min():12.0f} bytes ({df['L2_Footprint_bytes'].min()/1024:.1f} KB)")
        print(f"  Max:    {df['L2_Footprint_bytes'].max():12.0f} bytes ({df['L2_Footprint_bytes'].max()/1024:.1f} KB)")
        print(f"  Mean:   {df['L2_Footprint_bytes'].mean():12.0f} bytes ({df['L2_Footprint_bytes'].mean()/1024:.1f} KB)")
        print(f"  Median: {df['L2_Footprint_bytes'].median():12.0f} bytes ({df['L2_Footprint_bytes'].median()/1024:.1f} KB)")

    print(f"\nLatency range:")
    print(f"  Min:    {df['Latency_cycles'].min():12.0f} cycles")
    print(f"  Max:    {df['Latency_cycles'].max():12.0f} cycles")
    print(f"  Mean:   {df['Latency_cycles'].mean():12.0f} cycles")
    print(f"  Median: {df['Latency_cycles'].median():12.0f} cycles")

    if 'Throughput_GFLOPS' in df.columns:
        print(f"\nThroughput range:")
        print(f"  Min:    {df['Throughput_GFLOPS'].min():12.2f} GFLOP/s")
        print(f"  Max:    {df['Throughput_GFLOPS'].max():12.2f} GFLOP/s")
        print(f"  Mean:   {df['Throughput_GFLOPS'].mean():12.2f} GFLOP/s")
        print(f"  Median: {df['Throughput_GFLOPS'].median():12.2f} GFLOP/s")

    if 'Energy_Slowdown' in df.columns and 'Latency_Slowdown' in df.columns:
        print(f"\nSlowdown analysis:")
        print(f"  Energy slowdown:")
        print(f"    Mean:   {df['Energy_Slowdown'].mean():6.2f}×")
        print(f"    Median: {df['Energy_Slowdown'].median():6.2f}×")
        print(f"    Best:   {df['Energy_Slowdown'].min():6.2f}×")
        print(f"    Worst:  {df['Energy_Slowdown'].max():6.2f}×")

        print(f"  Latency slowdown:")
        print(f"    Mean:   {df['Latency_Slowdown'].mean():6.2f}×")
        print(f"    Median: {df['Latency_Slowdown'].median():6.2f}×")
        print(f"    Best:   {df['Latency_Slowdown'].min():6.2f}×")
        print(f"    Worst:  {df['Latency_Slowdown'].max():6.2f}×")

    print()

def main():
    if len(sys.argv) < 2:
        print("Usage: python visualize_pareto_frontier.py <csv_file>")
        print("\nExample:")
        print("  python visualize_pareto_frontier.py pareto_frontier_small.csv")
        sys.exit(1)

    csv_file = sys.argv[1]

    if not Path(csv_file).exists():
        print(f"Error: File '{csv_file}' not found")
        sys.exit(1)

    # Print statistics
    print_statistics(csv_file)

    # Create visualizations
    plot_pareto_frontier(csv_file)

if __name__ == '__main__':
    main()
