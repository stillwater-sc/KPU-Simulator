# DFX: Domain Flow Execution Specification  
**Version 1.0 (Draft)**  

## Introduction  
Domain Flow Execution (DFX) is the virtual instruction set architecture (ISA) and intermediate representation (IR) for the Stillwater Knowledge Processing Unit (KPU). DFX provides a stable, forward-compatible abstraction of the Domain Flow Architecture, enabling compilers to target KPUs without requiring direct knowledge of hardware microarchitectural details.  

DFX serves as the execution model for **SURE programs**, translating high-level knowledge representations into a structured, flow-oriented IR. It defines the semantics of operand delivery, result-stationary scheduling, and concurrency management across the KPU pipeline.  

## Goals  
- **Portability**: DFX abstracts hardware-specific details, ensuring SURE programs can execute across multiple generations of KPUs.  
- **Expressiveness**: Captures domain-flow semantics including operand streaming, buffer occupancy, and credit-based flow control.  
- **Performance Transparency**: Provides annotations for energy-delay product (EDP), concurrency, and memory movement to guide compiler optimizations.  
- **Extensibility**: Designed to evolve with new KPU fabrics, precision formats, and scheduling strategies.  

## Execution Model  
- **Domain Flow Semantics**: Instructions represent flows of knowledge operands rather than scalar operations.  
- **Result-Stationary Scheduling**: Results remain in place while operands stream through the pipeline.  
- **Concurrency Annotations**: DFX encodes dependencies, buffer credits, and synchronization points explicitly.  
- **Energy-Aware Metadata**: Each instruction may carry optional annotations for power, latency, and throughput modeling.  

## Example (DFX Pseudocode)  
```  
// Matrix multiplication fragment in DFX IR
dfx.load_operand   A_tile, stream=0
dfx.load_operand   B_tile, stream=1
dfx.compute        matmul, A_tile, B_tile -> C_tile
dfx.store_result   C_tile, buffer=local, annotate(edp=low, concurrency=high)
```  

---

This intro positions **DFX** as the **PTX-equivalent layer** for Knowledge Processing Units (KPU): a virtual ISA that captures domain-flow semantics, while remaining extensible for future hardware.  

---

# Section 2: DFX Instruction Set Overview

DFX defines a set of **domain-flow primitives** that capture the execution semantics of knowledge-centric workloads. Unlike scalar ISAs, DFX instructions operate on **domain-structured operands** â€” tiles, tensors, constraint sets, or spectral bases â€” enabling distributed data flow efficiency across the KPU fabric.  

Each instruction encodes not only the operation but also **buffer credits**, **computational domain metadata**, and **fusion hints**, allowing compilers to orchestrate high-throughput execution with minimal programmer intervention.

---

## 2.1 Categories of Primitives

### ðŸ”¢ BLAS and Tensor Algebra
- **dfx.matmul** â€“ Matrix multiplication with operand streaming and result-stationary scheduling.  
- **dfx.axpy** â€“ Scaled vector addition with buffer credit annotations.  
- **dfx.tensor.contract** â€“ General tensor contraction across multiple dimensions.  
- **dfx.tensor.broadcast** â€“ Broadcast semantics for distributed operand flow.  

### ðŸ§© Constraint Solvers
- **dfx.constraint.solve** â€“ Iterative solver for linear/nonlinear constraint systems.  
- **dfx.constraint.project** â€“ Projection of solution candidates into feasible domains.  
- **dfx.constraint.update** â€“ Domain update with buffer-aware synchronization.  

### ðŸŒŠ Spectral Methods
- **dfx.fft** â€“ Fast Fourier Transform with distributed operand tiles.  
- **dfx.ifft** â€“ Inverse FFT with automatic operator fusion for post-processing.  
- **dfx.spectral.filter** â€“ Domain-specific filtering with credit-based operand flow.  

### ðŸŽ¶ DSP (Digital Signal Processing)
- **dfx.convolve** â€“ Streaming convolution with operand injection and buffer credits.  
- **dfx.fir** â€“ Finite impulse response filter with concurrency annotations.  
- **dfx.iir** â€“ Infinite impulse response filter with automatic fusion of feedback loops.  

### âš™ï¸ Model Predictive Control (MPC)
- **dfx.mpc.predict** â€“ Forward prediction of system states using domain-structured operands.  
- **dfx.mpc.optimize** â€“ Optimization of control inputs under constraints.  
- **dfx.mpc.update** â€“ Update of control horizon with buffer-aware synchronization.  

---

## 2.2 Domain-Structured Operands
Operands in DFX are **domain-structured**, meaning they carry metadata about:
- **Shape and tiling** (matrix tiles, tensor slices, spectral bases).  
- **Distribution** (how operands are partitioned across KPU fabrics).  
- **Credits** (buffer occupancy and flow control tokens).  
- **Fusion hints** (operators eligible for automatic fusion).  

This enables **distributed data flow efficiency**, where operands stream through computational domains without redundant movement.

---

## 2.3 Buffer Credits
DFX instructions explicitly encode **buffer credits**:
- **dfx.credit.allocate** â€“ Reserve buffer slots for operand streams.  
- **dfx.credit.release** â€“ Free buffer slots after result consumption.  
- **dfx.credit.sync** â€“ Synchronize credits across computational domains.  

Credits ensure **deadlock-free flow control** and maximize throughput in distributed pipelines.

---

## 2.4 Computational Domains
DFX organizes execution into **computational domains**:
- **Linear Algebra Domain** â€“ BLAS and tensor primitives.  
- **Constraint Domain** â€“ Solvers and projection operators.  
- **Spectral Domain** â€“ FFTs and spectral filters.  
- **Signal Domain** â€“ DSP primitives.  
- **Control Domain** â€“ MPC primitives.  

Domains provide **semantic grouping** and allow compilers to optimize scheduling and fusion within and across domains.

---

## 2.5 Automatic Operator Fusion
DFX supports **automatic operator fusion**:
- Fusion hints are carried in operand metadata.  
- Compatible operators (e.g., `fft â†’ filter â†’ ifft`) are fused into single execution flows.  
- Fusion reduces operand movement, buffer usage, and latency.  

Example:
```
// Spectral filtering pipeline with fusion
dfx.fft          signal -> spectrum
dfx.spectral.filter spectrum -> filtered
dfx.ifft         filtered -> output
// Compiler fuses into single domain-flow operator
```

---

## 2.6 Example: MPC Workflow
```
// Predictive control loop in DFX
dfx.mpc.predict   state, model -> horizon
dfx.mpc.optimize  horizon, constraints -> control
dfx.mpc.update    control -> state_next
dfx.credit.sync   domain=control
```

This illustrates **domain-structured operands**, **buffer credits**, and **fusion-ready operators** working together to yield distributed efficiency.

---

âœ¨ In short: **DFX is not just an IR â€” itâ€™s a flow-aware execution model** where primitives, operands, credits, and domains are first-class citizens. 

---

# Section 3: Memory and Flow Semantics

DFX departs from traditional scalar ISAs by treating **operand movement and flow control** as firstâ€‘class semantics. Instead of explicit load/store instructions, DFX encodes **streaming, buffering, and creditâ€‘based scheduling** to maximize distributed efficiency across the KPU fabric.

---

## 3.1 Operand Model

Operands in DFX are **domainâ€‘structured**:
- **Tiles and Tensors**: Partitioned into subâ€‘domains for distributed execution.  
- **Spectral Bases**: Represent frequencyâ€‘domain operands for FFT and DSP primitives.  
- **Constraint Sets**: Encapsulate feasible regions for solver domains.  
- **Predictive Horizons**: Structured operands for MPC domains.  

Each operand carries metadata:
- **Shape** (dimensions, tiling strategy).  
- **Distribution** (placement across KPU fabrics).  
- **Credits** (buffer occupancy tokens).  
- **Annotations** (energyâ€‘delay, concurrency, fusion hints).  

---

## 3.2 Resultâ€‘Stationary Scheduling

DFX adopts a **resultâ€‘stationary model**:
- Results remain in place within local buffers.  
- Operands stream through compute pipelines.  
- Reduces operand movement and global memory traffic.  
- Enables **fusion** of adjacent operators without redundant data transfers.  

Example:
```
dfx.matmul   A_tile, B_tile -> C_tile, result_stationary
dfx.axpy     C_tile, D_tile -> E_tile, fuse=on
```
Here, `C_tile` remains stationary, enabling fusion of matmul and axpy.

---

## 3.3 Buffer Credits

Buffer credits enforce **flow control**:
- **Allocation**: Credits represent available buffer slots.  
- **Consumption**: Instructions decrement credits when operands are injected.  
- **Release**: Credits are restored when results are consumed or stored.  
- **Synchronization**: Credits can be synchronized across domains to prevent deadlock.  

Credit semantics:
- `credit=+n` â†’ allocate n slots.  
- `credit=-n` â†’ release n slots.  
- `credit=auto` â†’ compilerâ€‘guided allocation.  

---

## 3.4 Computational Domains

Operands and instructions are grouped into **computational domains**:
- **Linear Algebra Domain**: BLAS and tensor primitives.  
- **Constraint Domain**: Solver and projection operators.  
- **Spectral Domain**: FFT, filtering, inverse transforms.  
- **Signal Domain**: DSP primitives.  
- **Control Domain**: MPC primitives.  

Domains provide:
- **Semantic grouping** for compiler optimization.  
- **Credit isolation** to prevent crossâ€‘domain interference.  
- **Fusion opportunities** within and across domains.  

---

## 3.5 Automatic Operator Fusion

Fusion is a **core semantic** in DFX:
- Adjacent operators within a domain may be fused automatically.  
- Fusion reduces operand movement and buffer usage.  
- Fusion improves energyâ€‘delay product (EDP).  
- Fusion hints (`fuse=on`) guide compiler heuristics.  

Example:
```
dfx.fft       signal -> spectrum
dfx.filter    spectrum -> filtered, fuse=on
dfx.ifft      filtered -> output
```
Compiler fuses FFT, filter, and inverse into a single spectral pipeline.

---

## 3.6 Example: Flowâ€‘Aware Tensor Contraction

```
dfx.tensor.load     A_tile, domain=0, credit=+4
dfx.tensor.load     B_tile, domain=1, credit=+4
dfx.tensor.contract A_tile, B_tile -> C_tile, result_stationary, annotate(edp=low)
dfx.tensor.reduce   C_tile -> R, fuse=on
dfx.tensor.store    R, buffer=global, credit=-4
```

This example demonstrates:
- **Structured operands** (tiles).  
- **Buffer credits** for flow control.  
- **Resultâ€‘stationary scheduling** for efficiency.  
- **Fusion** of contraction and reduction.  

---

âœ¨ Section 3 establishes DFX as a **flowâ€‘aware execution model**, where operands, credits, domains, and fusion are encoded explicitly. This is the key differentiator from PTX: instead of abstracting scalar threads, DFX abstracts **knowledge flows** across distributed fabrics.

---

# Section 4: Concurrency and Synchronization

This section defines how DFX encodes dependencies, (mem)branes (barriers), and flowâ€‘aware synchronization primitives across computational domains.

Concurrency in DFX is not expressed as threads or warps, but as **flows of spatial domain operands** across computational domains. Synchronization is achieved through **buffer credits, dependency annotations, and domain barriers**, ensuring distributed execution remains efficient and deadlockâ€‘free.

---

## 4.1 Dependency Semantics
DFX instructions carry explicit **dependency metadata**:
- **`dep=operand`** â€“ Instruction depends on completion of a specific operand stream.  
- **`dep=domain`** â€“ Instruction depends on completion of all flows in a computational domain.  
- **`dep=credit`** â€“ Instruction depends on availability of buffer credits.  

Dependencies are resolved by the KPU scheduler, enabling fineâ€‘grained concurrency without programmerâ€‘managed locks.

---

## 4.2 Flow Synchronization Primitives
DFX provides synchronization primitives tailored to domainâ€‘flow execution:

- **`dfx.sync.domain`** â€“ Barrier across all instructions in a computational domain.  
- **`dfx.sync.credit`** â€“ Synchronize buffer credits across operand streams.  
- **`dfx.sync.fusion`** â€“ Ensure fused operators complete before downstream flows begin.  
- **`dfx.sync.global`** â€“ Global barrier across all domains, used sparingly for full pipeline resets.  

---

## 4.3 Buffer Occupancy and Flow Control
Concurrency is governed by **buffer occupancy models**:
- Each buffer has a finite number of credits.  
- Instructions consume credits when injecting operands.  
- Credits are released when results are consumed or stored.  
- Occupancy annotations (`occupancy=high`, `occupancy=low`) guide compiler scheduling.  

This ensures **creditâ€‘based flow control**, preventing stalls and enabling distributed concurrency.

---

## 4.4 Computational Domain Synchronization
Domains may synchronize independently or cooperatively:
- **Intraâ€‘domain barriers**: Synchronize flows within BLAS, Tensor, Spectral, DSP, or MPC domains.  
- **Crossâ€‘domain synchronization**: Coordinate flows between domains (e.g., spectral preprocessing feeding into MPC optimization).  
- **Hierarchical synchronization**: Nested barriers allow fineâ€‘grained control over multiâ€‘domain pipelines.  

---

## 4.5 Automatic Fusion and Concurrency
Fusion interacts with concurrency:
- Fused operators execute as a single pipeline stage.  
- Dependencies collapse into fused flows, reducing synchronization overhead.  
- Compiler heuristics determine whether fusion improves concurrency or energyâ€‘delay product.  

Example:
```
dfx.fft        signal -> spectrum
dfx.filter     spectrum -> filtered, fuse=on
dfx.ifft       filtered -> output
dfx.sync.domain spectral
```
Here, FFT, filter, and inverse are fused, and the domain barrier ensures completion before downstream MPC flows.

---

## 4.6 Example: Concurrency in MPC
```
dfx.mpc.predict   state -> horizon, dep=credit
dfx.mpc.optimize  horizon -> control, dep=domain
dfx.mpc.update    control -> state_next
dfx.sync.credit   domain=control
```
This example shows:
- Prediction depends on buffer credits.  
- Optimization depends on completion of the prediction domain.  
- Update executes after optimization, with credit synchronization ensuring flow continuity.  

---

âœ¨ Section 4 establishes DFX as a **flowâ€‘aware concurrency model**, where synchronization is achieved through **dependencies, buffer credits, and domain barriers** rather than threads or locks. This makes concurrency explicit, analyzable, and energyâ€‘aware.

---

# Section 5: Energyâ€‘Delay and Performance Modeling

DFX integrates **energyâ€‘delay product (EDP) modeling** directly into its instruction semantics. Unlike traditional ISAs, where performance is measured externally, DFX instructions carry **metadata annotations** that allow compilers and runtime systems to optimize for throughput, latency, and energy efficiency simultaneously.

This section formalizes how DFX instructions embed **energyâ€‘aware annotations, concurrency hints, and sustainability metrics**, making performance modeling a firstâ€‘class concern in the IR.

---

## 5.1 Energyâ€‘Aware Annotations
Each DFX instruction may include optional **energyâ€‘aware metadata**:
- **`edp=low|medium|high`** â€“ Compilerâ€‘guided annotation of expected energyâ€‘delay product.  
- **`power=watts`** â€“ Estimated power consumption for operand flow.  
- **`latency=cycles`** â€“ Expected latency for instruction completion.  
- **`throughput=ops/sec`** â€“ Sustained throughput under steadyâ€‘state flow.  

Annotations are advisory, allowing compilers to balance **performance vs sustainability**.

---

## 5.2 Concurrency Hints
Concurrency is modeled explicitly:
- **`concurrency=high`** â€“ Instruction is amenable to parallel operand injection.  
- **`concurrency=low`** â€“ Instruction requires serialized execution.  
- **`occupancy=n`** â€“ Expected buffer occupancy during execution.  
- **`fusion_hint`** â€“ Indicates whether fusion improves concurrency or energy efficiency.  

These hints guide the scheduler in **credit allocation and domain synchronization**.

---

## 5.3 Sustainability Metrics
DFX embeds **sustainability metrics** to support energyâ€‘aware synthesis:
- **Carbon Intensity**: `carbon=grams` per operation, derived from runtime profiling.  
- **Thermal Budget**: `thermal=joules` per domain execution.  
- **Efficiency Index**: `eff_index` = ops / joule, compilerâ€‘computed.  

These metrics enable **architectural tradeoffs** between raw performance and longâ€‘term sustainability.

---

## 5.4 Performance Modeling Primitives
DFX provides primitives for modeling performance:
- **`dfx.profile`** â€“ Collect runtime statistics for EDP, latency, and throughput.  
- **`dfx.annotate`** â€“ Attach compilerâ€‘generated performance metadata to instructions.  
- **`dfx.optimize`** â€“ Reconfigure operand flow to minimize energyâ€‘delay product.  
- **`dfx.balance`** â€“ Balance concurrency and buffer credits across domains.  

---

## 5.5 Example: Energyâ€‘Aware Tensor Contraction
```
dfx.tensor.load     A_tile, domain=0, credit=+4
dfx.tensor.load     B_tile, domain=1, credit=+4
dfx.tensor.contract A_tile, B_tile -> C_tile, 
                    result_stationary, 
                    annotate(edp=low, concurrency=high, power=12W, latency=32cyc)
dfx.tensor.reduce   C_tile -> R, fuse=on, annotate(edp=medium, throughput=2e9 ops/sec)
dfx.tensor.store    R, buffer=global, credit=-4
```

This example demonstrates:
- **Energyâ€‘aware annotations** guiding compiler scheduling.  
- **Concurrency hints** enabling parallel operand injection.  
- **Fusion** reducing energyâ€‘delay product.  
- **Buffer credits** ensuring flow control.  

---

## 5.6 Sustainabilityâ€‘Driven Scheduling
Schedulers may prioritize:
- **Energy minimization** (low EDP, low carbon intensity).  
- **Latency minimization** (low cycle counts).  
- **Throughput maximization** (high ops/sec).  
- **Balanced sustainability** (efficiency index optimization).  

DFX makes these tradeoffs explicit, allowing compilers and runtime systems to adapt execution strategies dynamically.

---

DFX is a **sustainabilityâ€‘aware IR**, where energy, delay, and concurrency are encoded directly into the execution model. This is a key differentiator from PTX: DFX is not just about performance, but about **energyâ€‘efficient execution and data flow** across distributed fabrics.

---

# Section 6: Instruction Encoding and Syntax

This section defines the canonical format of DFX instructions, much like PTXâ€™s assemblyâ€‘style syntax, but adapted to the **domainâ€‘flow model** of KPUs.

DFX instructions are expressed in a **threeâ€‘part canonical format**:

```
<mnemonic> <operands> [ , <annotations> ]
```

Where:
- **Mnemonic**: Identifies the domainâ€‘flow primitive (e.g., `dfx.matmul`, `dfx.fft`).  
- **Operands**: Domainâ€‘structured inputs and outputs (tiles, tensors, constraint sets, signals, horizons).  
- **Annotations**: Optional metadata for buffer credits, concurrency, energyâ€‘delay, and fusion hints.  

---

## 6.1 Mnemonics

DFX mnemonics are **domainâ€‘prefixed** to reflect computational categories:

- **BLAS/Tensor Algebra**: `dfx.matmul`, `dfx.axpy`, `dfx.tensor.contract`  
- **Constraint Solvers**: `dfx.constraint.solve`, `dfx.constraint.project`  
- **Spectral Methods**: `dfx.fft`, `dfx.ifft`, `dfx.spectral.filter`  
- **DSP**: `dfx.convolve`, `dfx.fir`, `dfx.iir`  
- **MPC**: `dfx.mpc.predict`, `dfx.mpc.optimize`, `dfx.mpc.update`  
- **Synchronization**: `dfx.sync.domain`, `dfx.sync.credit`, `dfx.sync.global`  

---

## 6.2 Operand Encoding

Operands are **domainâ€‘structured objects** with metadata:

```
<operand_name> [ , domain=<id> , tile=<shape> , dist=<policy> ]
```

Examples:
- `A_tile, domain=0, tile=64x64, dist=cyclic`  
- `horizon, domain=control, tile=rolling, dist=distributed`  

---

## 6.3 Annotation Syntax

Annotations are encoded as **key=value pairs** following operands:

- **Buffer Credits**: `credit=+n`, `credit=-n`, `credit=auto`  
- **Concurrency**: `concurrency=high|low`, `occupancy=n`  
- **Energyâ€‘Delay**: `edp=low|medium|high`, `power=watts`, `latency=cycles`, `throughput=ops/sec`  
- **Fusion**: `fuse=on|off`, `fusion_hint=auto`  

Annotations may be combined:
```
dfx.matmul A_tile, B_tile -> C_tile, credit=+4, edp=low, concurrency=high, fuse=on
```

---

## 6.4 Instruction Examples

### Example 1: BLAS Matmul
```
dfx.matmul   A_tile, B_tile -> C_tile, 
             domain=linear, 
             credit=+8, 
             result_stationary, 
             annotate(edp=low, concurrency=high)
```

### Example 2: Spectral Pipeline
```
dfx.fft      signal -> spectrum, credit=+2
dfx.filter   spectrum -> filtered, fuse=on, edp=medium
dfx.ifft     filtered -> output, credit=-2
dfx.sync.domain spectral
```

### Example 3: MPC Horizon Update
```
dfx.mpc.predict   state, model -> horizon, credit=+4, concurrency=high
dfx.mpc.optimize  horizon, constraints -> control, edp=low, fuse=on
dfx.mpc.update    control -> state_next, credit=-4
dfx.sync.credit   domain=control
```

---

## 6.5 Encoding Principles

- **Domainâ€‘Prefixed Mnemonics**: Ensure clarity and extensibility.  
- **Structured Operands**: Carry tiling, distribution, and domain metadata.  
- **Annotations as Firstâ€‘Class Citizens**: Energy, concurrency, and credits are encoded explicitly.  
- **Fusion Semantics**: Operators may be fused automatically, guided by annotations.  
- **Resultâ€‘Stationary Default**: Unless specified otherwise, results remain stationary in local buffers.  

---

âœ¨ Section 6 establishes DFX as a **virtual ISA with assemblyâ€‘style syntax**, but one that encodes **flows, credits, domains, and energy metrics** directly. This makes DFX both **compilerâ€‘friendly** and **architecturally transparent**, bridging highâ€‘level SURE programs with KPU execution.

---

# Section 7: Toolchain Integration

DFX is designed as the **intermediate execution layer** between highâ€‘level SURE programs and the Stillwater KPU hardware. Toolchain integration ensures that compilers, profilers, and runtime systems can leverage DFXâ€™s explicit flow semantics, buffer credits, and energyâ€‘aware annotations.

---

## 7.1 Compiler Frontâ€‘Ends
Highâ€‘level languages and frameworks (e.g., SURE, domainâ€‘specific DSLs) compile into DFX:
- **Parsing and Lowering**: Source programs are lowered into domainâ€‘flow primitives (`dfx.matmul`, `dfx.fft`, etc.).  
- **Operand Structuring**: Compiler emits domainâ€‘structured operands with tiling, distribution, and buffer metadata.  
- **Annotation Injection**: Energyâ€‘delay, concurrency, and fusion hints are inserted during optimization passes.  
- **Fusion Analysis**: Compiler heuristics determine which operators can be fused into single pipeline stages.  

---

## 7.2 Optimizer and Scheduler
The optimizer transforms DFX IR into hardwareâ€‘ready flows:
- **Credit Allocation**: Assigns buffer credits to prevent stalls and deadlocks.  
- **Domain Scheduling**: Orders computational domains to maximize concurrency.  
- **Energyâ€‘Aware Optimization**: Balances latency, throughput, and sustainability metrics.  
- **Fusion Realization**: Collapses adjacent operators into fused flows when beneficial.  

---

## 7.3 Runtime System
The runtime executes DFX instructions on the KPU fabric:
- **Operand Streaming**: Streams domainâ€‘structured operands into compute pipelines.  
- **Buffer Management**: Tracks credits, occupancy, and synchronization across domains.  
- **Dynamic Adaptation**: Adjusts scheduling based on runtime profiling (e.g., thermal budgets, EDP).  
- **Fault Tolerance**: Detects and recovers from flow stalls or buffer exhaustion.  

---

## 7.4 Profilers and Performance Tools
DFX integrates with profiling tools to expose **flowâ€‘aware metrics**:
- **Instruction Profiling**: Collects latency, throughput, and energy data per primitive.  
- **Domain Profiling**: Measures concurrency and buffer occupancy across computational domains.  
- **Sustainability Metrics**: Reports efficiency index (ops/joule) and carbon intensity.  
- **Visualization**: Generates Gantt charts of operand flows, buffer credits, and fusion pipelines.  

---

## 7.5 Debugging and Verification
DFX provides hooks for debugging:
- **Flow Tracing**: Logs operand movement and credit allocation.  
- **Domain Checkpoints**: Allows inspection of intermediate results in computational domains.  
- **Fusion Verification**: Ensures fused operators preserve semantic correctness.  
- **Energy Validation**: Confirms annotations match runtime measurements.  

---

## 7.6 Integration with External Frameworks
DFX can be integrated into broader toolchains:
- **Compiler Backâ€‘Ends**: LLVMâ€‘style backâ€‘ends can emit DFX IR for KPUs.  
- **Domain Libraries**: BLAS, Tensor, DSP, and MPC libraries can map directly to DFX primitives.  
- **Workflow Orchestration**: Distributed frameworks (e.g., MPI, task graphs) can schedule DFX domains as flow units.  
- **Business Integration**: Profiling outputs can feed into sustainability dashboards and valuation models.  

---

## 7.7 Example Workflow
```
SURE Program --> Compiler Front-End --> DFX IR
DFX IR --> Optimizer --> Annotated DFX (credits, fusion, EDP)
Annotated DFX --> Runtime System --> KPU Execution
Runtime System --> Profiler --> Performance & Sustainability Reports
```

---

âœ¨ Section 7 positions DFX as the **bridge between highâ€‘level parallel programs and hardware execution**, with compilers, optimizers, runtimes, and profilers all interacting through a flowâ€‘aware IR. This makes DFX not just an ISA, but a **toolchain ecosystem** for sustainable, domainâ€‘flow computation.

---

# Section 8: Example Endâ€‘toâ€‘End Compilation Flow

To illustrate DFX in practice, we walk through a **Spectral Model Predictive Control (MPC) workload**. This workload combines **spectral preprocessing** (FFT + filtering) with **predictive optimization** (MPC horizon update), showing how domainâ€‘flow primitives, buffer credits, and energy annotations interact across the toolchain.

---

## 8.1 Highâ€‘Level SURE Source

```sure
// SURE program fragment
signal = acquire_input()
spectrum = fft(signal)
filtered = spectral_filter(spectrum)
output = ifft(filtered)

horizon = predict_state(output, model)
control = optimize(horizon, constraints)
state_next = update(control)
```

---

## 8.2 Compiler Frontâ€‘End â†’ DFX IR

The compiler lowers SURE primitives into DFX instructions:

```
dfx.fft        signal -> spectrum, credit=+2
dfx.filter     spectrum -> filtered, fuse=on, edp=medium
dfx.ifft       filtered -> output, credit=-2

dfx.mpc.predict   output, model -> horizon, credit=+4, concurrency=high
dfx.mpc.optimize  horizon, constraints -> control, edp=low, fuse=on
dfx.mpc.update    control -> state_next, credit=-4
```

---

## 8.3 Optimizer and Scheduler

The optimizer transforms IR:
- **Fusion**: FFT + filter + IFFT fused into a single spectral domain pipeline.  
- **Credit Allocation**: Ensures spectral domain credits are balanced with MPC domain credits.  
- **Energy Annotations**: `edp=low` for MPC optimize, `edp=medium` for spectral filter.  
- **Concurrency Scheduling**: Predict and optimize domains scheduled concurrently where feasible.  

---

## 8.4 Runtime Execution on KPU

At runtime:
- **Operand Streaming**: Signal tiles stream into spectral domain buffers.  
- **Resultâ€‘Stationary Scheduling**: Spectrum results remain stationary while filter and inverse transform flow through.  
- **Buffer Credits**: Credits consumed and released as operands move between spectral and MPC domains.  
- **Domain Synchronization**: `dfx.sync.domain spectral` ensures spectral pipeline completes before MPC begins.  

---

## 8.5 Profiler Output

Profiler reports flowâ€‘aware metrics:

- **Spectral Domain**  
  - Latency: 48 cycles  
  - Power: 10 W  
  - Throughput: 1.2e9 ops/sec  
  - EDP: medium  

- **MPC Domain**  
  - Latency: 64 cycles  
  - Power: 12 W  
  - Throughput: 1.5e9 ops/sec  
  - EDP: low  
  - Efficiency Index: 125 Mops/joule  

Visualization:  
- Gantt chart shows operand streams across spectral and MPC domains.  
- Buffer occupancy chart shows credits allocated/released per domain.  
- Fusion pipeline diagram shows FFT + filter + IFFT collapsed into one stage.  

---

## 8.6 Endâ€‘toâ€‘End Summary

- **SURE Source** â†’ Highâ€‘level domain expressions.  
- **DFX IR** â†’ Flowâ€‘aware primitives with credits and annotations.  
- **Optimizer** â†’ Fusion, scheduling, energyâ€‘aware transformations.  
- **Runtime** â†’ Operand streaming, buffer credits, domain synchronization.  
- **Profiler** â†’ Latency, throughput, energy, sustainability metrics.  

This flow demonstrates how DFX makes **knowledge flows explicit**, enabling compilers and runtimes to optimize for **performance, concurrency, and sustainability** simultaneously.

---

âœ¨ Section 8 shows DFX in action: a **complete toolchain path** from source to execution to profiling. It highlights how DFX differs from PTX â€” not just an IR, but a **flowâ€‘aware execution ecosystem**.

---

# Section 9: Future Extensions

DFX is designed to evolve alongside emerging compute fabrics. Future extensions will expand DFX beyond standalone KPUs, enabling **hybrid architectures** and **novel accelerators** to participate in domainâ€‘flow execution. These extensions ensure DFX remains a unified abstraction for heterogeneous, sustainable computation.

---

## 9.1 Hybrid CPU/KPU Systems

Taking inspiration from unified CPU/GPU designs such as the NVIDIA Grace Hopper Superchip, DFX envisions **tight integration between CPUs and KPUs**:

- **Unified Memory Model**  
  - Shared address space between CPU and KPU domains.  
  - Zeroâ€‘copy operand exchange via domainâ€‘structured buffers.  
  - Credits extended across CPU and KPU pipelines for consistent flow control.  

- **Crossâ€‘Domain Scheduling**  
  - CPU handles scalar, controlâ€‘heavy tasks (e.g., orchestration, branching).  
  - KPU executes domainâ€‘flow primitives (BLAS, spectral, MPC).  
  - DFX encodes synchronization primitives (`dfx.sync.hybrid`) to coordinate CPU/KPU execution.  

- **Compiler Integration**  
  - Frontâ€‘ends emit hybrid IR, partitioning workloads between CPU and KPU.  
  - Optimizer balances latencyâ€‘sensitive CPU tasks with throughputâ€‘optimized KPU flows.  
  - Profilers report unified metrics across both fabrics.  

Example:
```
dfx.hybrid.load    operand -> CPU_domain
dfx.hybrid.transfer CPU_domain -> KPU_domain, credit=+2
dfx.mpc.optimize   horizon -> control, domain=KPU, edp=low
dfx.hybrid.sync    CPU_domain, KPU_domain
```

---

## 9.2 Optical Matmul Engines

Future KPUs may integrate **optical matrix multiplication accelerators**, leveraging photonic computing for ultraâ€‘lowâ€‘latency linear algebra:

- **Optical Operand Streaming**  
  - Operands encoded as light patterns, streamed into optical matmul units.  
  - DFX introduces `dfx.optical.matmul` for photonic execution.  

- **Spectral Fusion**  
  - Optical matmul naturally aligns with spectral methods.  
  - Fusion pipelines (`fft â†’ optical matmul â†’ ifft`) reduce operand movement.  

- **Annotations**  
  - `latency=picoseconds`, `power=milliwatts` reflect optical efficiency.  
  - `fusion_hint=optical` guides compiler to prefer photonic paths.  

Example:
```
dfx.optical.matmul A_tile, B_tile -> C_tile, 
                   credit=+1, latency=ps, power=mW, fusion_hint=optical
```

---

## 9.3 Optical Spectral Engines

Beyond matmul, **optical spectral engines** can accelerate FFTs and filtering:

- **Optical FFT** (`dfx.optical.fft`)  
  - Executes transforms in photonic domain with nearâ€‘zero latency.  
- **Optical Filtering** (`dfx.optical.filter`)  
  - Implements spectral filters directly in optical hardware.  
- **Hybrid Fusion**  
  - Optical FFT + filter fused with electronic MPC domains.  
  - Compiler emits hybrid flows with optical/electronic synchronization.  

---

## 9.4 Unified Hybrid Flow Semantics

DFX extensions unify CPU, KPU, and optical accelerators under one flow model:

- **Hybrid Credits**: Credits span across CPU, KPU, and optical buffers.  
- **Crossâ€‘Fabric Synchronization**: `dfx.sync.hybrid` coordinates heterogeneous domains.  
- **Energyâ€‘Delay Modeling**: Sustainability metrics extended to optical engines.  
- **Composable Domains**: CPU, KPU, and optical engines treated as interchangeable computational domains.  

---

## 9.5 Example: Hybrid Spectral MPC Workflow

```
dfx.hybrid.load     signal -> CPU_domain
dfx.optical.fft     signal -> spectrum, credit=+2, latency=ps
dfx.optical.filter  spectrum -> filtered, fuse=on
dfx.optical.ifft    filtered -> output, credit=-2
dfx.mpc.predict     output, model -> horizon, domain=KPU
dfx.mpc.optimize    horizon, constraints -> control, edp=low
dfx.hybrid.sync     CPU_domain, KPU_domain, Optical_domain
```

This workflow demonstrates:
- CPU orchestration of input acquisition.  
- Optical FFT/filter pipeline for spectral preprocessing.  
- KPU MPC optimization for control synthesis.  
- Hybrid synchronization across all fabrics.  

---

âœ¨ Section 9 positions DFX as a **futureâ€‘proof IR**, capable of spanning **CPU/KPU hybrids** and **optical accelerators**. By embedding flow semantics, buffer credits, and sustainability metrics across heterogeneous fabrics, DFX ensures unified, efficient execution for nextâ€‘generation knowledge workloads.

---

# Section 10: Comparative Positioning

This section situates DFX relative to other intermediate representations and execution abstractions, highlighting how it uniquely addresses **flow semantics, sustainability, and hybrid integration**.

DFX occupies a distinct niche among intermediate representations (IRs) and virtual ISAs. While it shares certain traits with PTX, LLVM IR, and domainâ€‘specific DSLs, DFX is differentiated by its **domainâ€‘flow orientation**, **explicit energy modeling**, and **hybrid extensibility**.

---

## 10.1 DFX vs PTX (NVIDIA CUDA)

- **PTX**  
  - Threadâ€‘centric abstraction for CUDA programs.  
  - Models scalar/vector instructions executed by GPU warps.  
  - Focuses on portability across NVIDIA GPU generations.  

- **DFX**  
  - Flowâ€‘centric abstraction for SURE programs on KPUs.  
  - Models operand streams, buffer credits, and domainâ€‘structured primitives.  
  - Focuses on distributed efficiency, sustainability, and hybrid CPU/KPU integration.  

**Key Differentiator**: PTX abstracts threads; DFX abstracts flows. PTX hides energy; DFX encodes energy explicitly.

---

## 10.2 DFX vs LLVM IR

- **LLVM IR**  
  - Generalâ€‘purpose, lowâ€‘level IR for compiler toolchains.  
  - Instruction set is scalar and hardwareâ€‘agnostic.  
  - Optimizations focus on control flow, SSA form, and generic performance.  

- **DFX**  
  - Domainâ€‘specific IR for knowledge flows.  
  - Instruction set includes BLAS, spectral, DSP, constraint, and MPC primitives.  
  - Optimizations focus on buffer credits, operator fusion, and energyâ€‘delay product.  

**Key Differentiator**: LLVM IR is universal but scalar; DFX is specialized and flowâ€‘aware.

---

## 10.3 DFX vs Domainâ€‘Specific DSLs (e.g., TensorFlow XLA, Halide)

- **DSL IRs**  
  - Capture domainâ€‘specific operations (tensor algebra, image pipelines).  
  - Often embed fusion and scheduling heuristics.  
  - Limited portability beyond their domain.  

- **DFX**  
  - Captures multiple computational domains (linear algebra, spectral, DSP, MPC).  
  - Provides unified flow semantics across heterogeneous fabrics (CPU, KPU, optical).  
  - Designed for extensibility into new domains (quantum, neuromorphic).  

**Key Differentiator**: DSL IRs are siloed; DFX is unified across domains and fabrics.

---

## 10.4 DFXâ€™s Unique Contributions

- **Flowâ€‘Aware Execution**: Operands stream through pipelines with explicit buffer credits.  
- **Resultâ€‘Stationary Scheduling**: Results remain in place, reducing operand movement.  
- **Energyâ€‘Delay Modeling**: EDP, power, latency, and sustainability metrics embedded in IR.  
- **Automatic Fusion**: Operators fused into pipelines to minimize energy and latency.  
- **Hybrid Integration**: Unified semantics across CPU, KPU, and optical accelerators.  
- **Futureâ€‘Proof Domains**: Extensible to quantum, neuromorphic, and other emerging fabrics.  

---

## 10.5 Strategic Positioning

- **For Engineers**: DFX is a precise, analyzable IR that makes concurrency, credits, and energy explicit.  
- **For Toolchains**: DFX is a bridge between highâ€‘level SURE programs and heterogeneous hardware fabrics.  
- **For Industry**: DFX positions Stillwater KPUs as part of a **sustainable, hybrid compute ecosystem**, analogous to how PTX positioned CUDA GPUs as programmable accelerators.  

---

âœ¨ Section 10 establishes DFXâ€™s **comparative identity**: not just another IR, but a **flowâ€‘centric, energyâ€‘aware, hybridâ€‘ready execution abstraction**. It stands apart from PTX, LLVM IR, and DSLs by unifying **knowledge flows, sustainability, and heterogeneous integration**.

---

# Section 11: Conclusion and Roadmap

This section summarizes the vision and lay out next steps for adoption, tooling, and future evolution.

## 11.1 Conclusion  
Domain Flow Execution (DFX) establishes a new paradigm for intermediate representation and virtual ISA design. Unlike threadâ€‘centric abstractions such as PTX, DFX encodes **flows of knowledge operands**, **buffer credits**, and **domainâ€‘structured primitives** as firstâ€‘class citizens.  

By embedding **energyâ€‘delay modeling**, **automatic operator fusion**, and **hybrid integration** into its core semantics, DFX provides a sustainable, extensible foundation for executing SURE programs on Stillwater KPUs and beyond.  

DFX is not just an IR â€” it is a **flowâ€‘aware execution ecosystem** that unifies compilers, runtimes, profilers, and heterogeneous accelerators under a single abstraction.

---

## 11.2 Roadmap

### Phase 1: Reference Implementation
- Develop a **DFX reference interpreter** for KPUs.  
- Provide **compiler frontâ€‘end support** for SURE programs.  
- Release **sample workloads** (BLAS, spectral, MPC) to validate flow semantics.  

### Phase 2: Toolchain Integration
- Integrate DFX into **LLVMâ€‘style backâ€‘ends** for broader compiler adoption.  
- Build **profiling and visualization tools** (Gantt charts, buffer occupancy, EDP dashboards).  
- Enable **debugging hooks** for operand tracing and fusion verification.  

### Phase 3: Hybrid CPU/KPU Systems
- Extend DFX with **hybrid synchronization primitives** (`dfx.sync.hybrid`).  
- Implement **unified memory models** for CPU/KPU operand exchange.  
- Pilot workloads demonstrating **CPU orchestration + KPU flow execution**.  

### Phase 4: Optical Accelerator Integration
- Introduce **optical matmul and spectral primitives** (`dfx.optical.matmul`, `dfx.optical.fft`).  
- Validate **photonic fusion pipelines** for ultraâ€‘low latency workloads.  
- Extend sustainability metrics to include **optical efficiency indices**.  

### Phase 5: Future Domains
- Explore extensions for **quantum flows** (qubitâ€‘structured operands).  
- Investigate **neuromorphic integration** for spiking knowledge flows.  
- Position DFX as a **unified IR for heterogeneous, sustainable computation**.  

---

## 11.3 Strategic Vision
DFX positions Stillwater KPUs as part of a **nextâ€‘generation compute ecosystem**, where:
- **Engineers** gain precise, analyzable flow semantics.  
- **Toolchains** gain a unified IR for heterogeneous fabrics.  
- **Industry** gains a sustainable, futureâ€‘proof execution model.  

By bridging **knowledge flows, sustainability, and hybrid integration**, DFX charts a roadmap toward **robust, scalable, and energyâ€‘aware computation** across CPUs, KPUs, optical accelerators, and beyond.

---

âœ¨ With Section 11, the specification is complete: DFX is defined not only as a technical abstraction but as a **strategic framework for the future of domainâ€‘flow computing**.


